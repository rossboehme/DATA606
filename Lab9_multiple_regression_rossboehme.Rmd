---
title: "Multiple linear regression"
author: ""
output:
  html_document:
    includes:
      in_header: header.html
    css: ./lab.css
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, message = FALSE, warning = FALSE)
```

## Grading the professor

Many college courses conclude by giving students the opportunity to evaluate the course and the instructor anonymously. However, the use of these student evaluations as an indicator of course quality and teaching effectiveness is often criticized because these measures may reflect the influence of non-teaching related characteristics, such as the physical appearance of the instructor. The article titled, "Beauty in the classroom: instructors' pulchritude and putative pedagogical productivity" by Hamermesh and Parker found that instructors who are viewed to be better looking receive higher instructional ratings. 

Here, you will analyze the data from this study in order to learn what goes into a positive professor evaluation.

## Getting Started

### Load packages

In this lab, you will explore and visualize the data using the **tidyverse** suite of packages. The data can be found in the companion package for OpenIntro resources, **openintro**.

Let's load the packages.

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(GGally)
```

This is the first time we're using the `GGally` package. You will be using the `ggpairs` function from this package later in the lab.

### The data

The data were gathered from end of semester student evaluations for a large sample of professors from the University of Texas at Austin. In addition, six students rated the professors' physical appearance. The result is a data frame where each row contains a different course and columns represent variables about the courses and professors. It's called `evals`.

```{r}
glimpse(evals)
```

We have observations on 21 different variables, some categorical and some numerical. The meaning of each variable can be found by bringing up the help file:

```{r help-evals, eval=FALSE}
?evals
```

## Exploring the data

1.  Is this an observational study or an experiment? The original research
    question posed in the paper is whether beauty leads directly to the
    differences in course evaluations. Given the study design, is it possible to
    answer this question as it is phrased? If not, rephrase the question.
  
- ANSWER: Observational studies are observing a variable naturally, without intervening (which would be an experiment). That is what's occurring here. 
- ANSWER: Whether beauty leads "directly" to the difference in course evaluations (causation) cannot be *proven*. The probability of a connection between the two is what can be assessed. A better, re-phrased question might be: Based on these data, does there appear to be an association between perceived beauty scores and course evaluation scores?

2.  Describe the distribution of `score`. Is the distribution skewed? What does 
    that tell you about how students rate courses? Is this what you expected to 
    see? Why, or why not?
  
- ANSWER: This distribution is negatively or left skewed, with the average of the ratings (roughly 4.2) higher than the average of the scale (2.5). Students tend to give positive ("above (scale) average") reviews. This is approximately what I expected due to survivorship bias: Teachers who manage to become and stay as professors tend to be good teachers.                                                                                                                                                                         
```{r}
ggplot(evals,aes(x=score)) +
  geom_histogram()
```

3.  Excluding `score`, select two other variables and describe their relationship 
    with each other using an appropriate visualization.

- ANSWER: Below I look at the relationship between age and average beauty score. There's no obvious relationship between age and beauty score. Perhaps at the high end of "bty_avg" the "age" tends to be younger. 
    
```{r}
ggplot(data = evals, aes(x = age, y = bty_avg)) +
  geom_jitter() +
  geom_point()
```

## Simple linear regression

The fundamental phenomenon suggested by the study is that better looking teachers are evaluated more favorably. Let's create a scatterplot to see if this appears to be the case:

```{r scatter-score-bty_avg}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_point()
```

Before you draw conclusions about the trend, compare the number of observations in the data frame with the approximate number of points on the scatterplot. Is anything awry?

- The dataframe "evals" has 464 observations and there are appear to be fewer points on the scatterplot, perhaps due to missing "score" or "bty_avg" values. 

```{r}
nrow(evals)
```

4.  Replot the scatterplot, but this time use `geom_jitter` as your layer. What 
    was misleading about the initial scatterplot?
  
- ANSWER: The scatterplot had many observations with highly similar values, such that they couldn't be differentiated graphically on the scatterplot. The jitter fixes this. 

```{r scatter-score-bty_avg-jitter}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter()
```

5.  Let's see if the apparent trend in the plot is something more than
    natural variation. Fit a linear model called `m_bty` to predict average
    professor score by average beauty rating. Write out the equation for the linear 
    model and interpret the slope. Is average beauty score a statistically significant
    predictor? Does it appear to be a practically significant predictor?
    
- ANSWER: y hat m_bty = 3.88034 (y intercept) + 0.06664*evals$bty_avg 
- ANSWER: Interpretation of slope: Assuming a base of 3.88 score at 0 bty_avg, for every increase of 1 in bty_avg, score increases by 0.06664.
- ANSWER: Average beauty score appears to be a statistically significant, with a p value of 0.0000508. Assuming a standard significance threshold of less than 0.05 (likelihood of relationship occurring due to randomness), the average beauty score `bty_avg` appears to be a statistically significant predictor of the average professor evaluation score `score`.

```{r}
m_bty <- lm(score ~ bty_avg, data=evals)
summary(m_bty)
```

    
Add the line of the best fit model to your plot using the following:
    
```{r scatter-score-bty_avg-line-se}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  geom_smooth(method = "lm")
```

The blue line is the model. The shaded gray area around the line tells you about the variability you might expect in your predictions. To turn that off, use `se = FALSE`.

```{r scatter-score-bty_avg-line}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE)
```

6.  Use residual plots to evaluate whether the conditions of least squares
    regression are reasonable. Provide plots and comments for each one (see
    the Simple Regression Lab for a reminder of how to make these).
    
- ANSWER: Conditions of least squares regression: 1) Linearity; 2) Nearly normal residuals; 3) Constant variability. Each is evaluated below:

**Linearity**: Relationship appears linear. The variability of the residuals is approximately constant across the distribution, without curvature or indication of non-normality. There is no apparent pattern in the residuals plot, which indicates that the relationship is linear. The linear model is approximating the data points without favoring certain inputs.

```{r linearity-eval}
ggplot(data = m_bty, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")
```

**Nearly normal residuals**: Normal probability plot of the residuals below. The relationship between "theoretical" and "sample" appears generally linear. There is a skew at higher values, however not enough to describe the relationship as non-linear. 

```{r nn-res}
ggplot(data = m_bty, aes(sample = .resid)) +
  stat_qq()
```

**Constant variability**: The constant variability condition states that the variability of points around the least squares line should be roughly constant. When I plotted using qqnorm and qqline below, there was a roughly constant relationship between the two axes. Therefore, yes, the constant variability condition appears to be met.

```{r}
qqnorm(m_bty$residuals)
qqline(m_bty$residuals)
```


## Multiple linear regression

The data set contains several variables on the beauty score of the professor: individual ratings from each of the six students who were asked to score the physical appearance of the professors and the average of these six scores. Let's take a look at the relationship between one of these scores and the average beauty score.

```{r bty-rel}
ggplot(data = evals, aes(x = bty_f1lower, y = bty_avg)) +
  geom_point()

evals %>% 
  summarise(cor(bty_avg, bty_f1lower))
```

As expected, the relationship is quite strong---after all, the average score is calculated using the individual scores. You can actually look at the relationships between all beauty variables (columns 13 through 19) using the following command:

```{r bty-rels}
evals %>%
  select(contains("bty")) %>%
  ggpairs()
```

These variables are collinear (correlated), and adding more than one of these variables to the model would not add much value to the model. In this application and with these highly-correlated predictors, it is reasonable to use the average beauty score as the single representative of these variables.

In order to see if beauty is still a significant predictor of professor score after you've accounted for the professor's gender, you can add the gender term into the model.

```{r scatter-score-bty_avg_pic-color}
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)
summary(m_bty_gen)
```

7.  P-values and parameter estimates should only be trusted if the
    conditions for the regression are reasonable. Verify that the conditions
    for this model are reasonable using diagnostic plots.

Linearity evaluation: Even spread and no pattern of values in the plot, with constant (flat) variability. Relationship appears linear. 

```{r linearity-eval2}
ggplot(data = m_bty_gen, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")
```

Nearly normal residuals evaluation: As with m_bty model, there is a skew at higher values of theoretical and sample, but the relationship is still linear.

```{r nn-res2}
ggplot(data = m_bty_gen, aes(sample = .resid)) +
  stat_qq()
```

Constant variability evaluation: Variability of points around the least squares line is roughly constant. Therefore the constant variability condition has been met. 

```{r}
qqnorm(m_bty$residuals)
qqline(m_bty$residuals)
```


8.  Is `bty_avg` still a significant predictor of `score`? Has the addition
    of `gender` to the model changed the parameter estimate for `bty_avg`?
    
- ANSWER: Re-running m_bty_gen model summary below. bty_avg remains a statistically significant predictor of `score` with a p value of 0.00000648.
- ANSWER: Before adding gender to the model, the equation for score ~ beauty model was y hat m_bty = 3.88034 (y intercept) + 0.06664(bty_avg). After adding gender to the model, the equation for the score ~ beauty + gender is y hat m_bty_gen = 3.74734 + 0.07416(bty_avg) + 0.17239(gendermale).
- ANSWER: Interpretation of slope: Assuming a base of 3.74734 score at 0 bty_avg, for every increase of 1 in bty_avg, score increases by 0.07416 and for every increase of 1 in gendermale (which is a binary variable), score increases by 0.17239. It's not only more attractive professors who get higher average course evaluation scores but also male professors.

```{r}
summary(m_bty_gen)
```

Note that the estimate for `gender` is now called `gendermale`. You'll see this name change whenever you introduce a categorical variable. The reason is that R recodes `gender` from having the values of `male` and `female` to being an indicator variable called `gendermale` that takes a value of $0$ for female professors and a value of $1$ for male professors. (Such variables are often referred to as "dummy" variables.)

As a result, for female professors, the parameter estimate is multiplied by zero, leaving the intercept and slope form familiar from simple regression.

\[
  \begin{aligned}
\widehat{score} &= \hat{\beta}_0 + \hat{\beta}_1 \times bty\_avg + \hat{\beta}_2 \times (0) \\
&= \hat{\beta}_0 + \hat{\beta}_1 \times bty\_avg\end{aligned}
\]

<!-- We can plot this line and the line corresponding to those with color pictures
with the following  -->
<!-- custom function. -->

```{r twoLines}
ggplot(data = evals, aes(x = bty_avg, y = score, color = pic_color)) +
 geom_smooth(method = "lm", formula = y ~ x, se = FALSE)
```

9.  What is the equation of the line corresponding to those with color pictures? 
    (*Hint:* For those with color pictures, the parameter estimate is multiplied
    by 1.) For two professors who received the same beauty rating, which color 
    picture tends to have the higher course evaluation score?
    
- ANSWER: The equation of the line with color pictures is the line of best fit for score ~ bty_avg for the two different pic colors. In numeric terms it is y hat = 4.06318 (y intercept) + 0.05548(bty_avg) + -0.16059(pic_colorcolor) where if a given professor's photo is in color the pic_colorcolor value is 1. 
-ANSWER: For two professors who receive the same beauty rating, black and white photos tend to have a higher course evaluation score. 

```{r}
m_pic_color <- lm(score ~ bty_avg + pic_color,data=evals)
summary(m_pic_color)
```

The decision to call the indicator variable `gendermale` instead of `genderfemale` has no deeper meaning. R simply codes the category that comes first alphabetically as a $0$. (You can change the reference level of a categorical variable, which is the level that is coded as a 0, using the`relevel()` function. Use `?relevel` to learn more.)

10. Create a new model called `m_bty_rank` with `gender` removed and `rank` 
    added in. How does R appear to handle categorical variables that have more 
    than two levels? Note that the rank variable has three levels: `teaching`, 
    `tenure track`, `tenured`.

ANSWER:
- If there are categorical variables with more than 2 levels, R will have one act as the base value (e.g. teaching = 0), with "ranktenure track" and "ranktenured" broken out as their own variables which can be 0 or 1. 

```{r}
m_bty_rank<- lm(score ~ bty_avg + rank, data=evals)
summary(m_bty_rank)
table(evals$rank)
```

The interpretation of the coefficients in multiple regression is slightly different from that of simple regression. The estimate for `bty_avg` reflects how much higher a group of professors is expected to score if they have a beauty rating that is one point higher *while holding all other variables constant*. In this case, that translates into considering only professors of the same rank with `bty_avg` scores that are one point apart.

## The search for the best model

We will start with a full model that predicts professor score based on rank, gender, ethnicity, language of the university where they got their degree, age, proportion of students that filled out evaluations, class size, course level, number of professors, number of credits, average beauty rating, outfit, and picture color.

11. Which variable would you expect to have the highest p-value in this model? 
    Why? *Hint:* Think about which variable would you expect to not have any 
    association with the professor score.

- ANSWER: The variable with the highest p-value which I'd therefore not expect to have much association with the professor's score is cls_students because students would likely account for the professor's teaching quality within the limitations of class size -- something out of their control.

Let's run the model...

```{r m_full, tidy = FALSE}
m_full <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg 
             + pic_outfit + pic_color, data = evals)
summary(m_full)
```

12. Check your suspicions from the previous exercise. Include the model output
    in your response.
  
- ANSWER: I wasn't correct as cls_students had the third highest p-value of 0.22896, behind cls_profssingle and cls_levelupper which had 0.77806 and 0.29369 respectively. 

13. Interpret the coefficient associated with the ethnicity variable.
- ANSWER: For every increase in 1 of the value of ethnicitynot minority (which is a binary variable), the average professor evaluation score `score` increased by 0.1234929. However this was not a statistically significant finding, therefore it should be dropped from the model.

14. Drop the variable with the highest p-value and re-fit the model. Did the
    coefficients and significance of the other explanatory variables change?
    (One of the things that makes multiple regression interesting is that
    coefficient estimates depend on the other variables that are included in
    the model.) If not, what does this say about whether or not the dropped
    variable was collinear with the other explanatory variables?

- ANSWER: Collinearity will inflate the variance, standard error, and p-value of coefficient estimates. When I droped cls_profs because it had the highest p-value, it did slightly decrease the p-value of most other predictors. therefore cls_profs had some collinearity with other predictors. When I dropped cls_profs, in addition to the signifiance levels changing, the coefficients also changed slightly.

```{r m_full_adj1}
m_no_cls_profs <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_credits + bty_avg 
             + pic_outfit + pic_color, data = evals)
summary(m_no_cls_profs)
```

15. Using backward-selection and p-value as the selection criterion,
    determine the best model. You do not need to show all steps in your
    answer, just the output for the final model. Also, write out the linear
    model for predicting score based on the final model you settle on.

- ANSWER: This model has the highest R-squared while also having statistical significance for all the predictors. 

```{r}
m_best <- lm(score ~ gender + ethnicity + language + age + cls_perc_eval + 
              cls_credits + bty_avg + pic_color, data = evals)
summary(m_best)
```

16. Verify that the conditions for this model are reasonable using diagnostic 
    plots.
    
- ANSWER: (Graphed below via plot() function) Residuals vs. Fitted plot shows linearity via even spread and constant variability. Nearly normal residuals plot has skew at lowest and highest values but is generally linear; condition is met.

```{r}
plot(m_best)
```

17. The original paper describes how these data were gathered by taking a
    sample of professors from the University of Texas at Austin and including 
    all courses that they have taught. Considering that each row represents a 
    course, could this new information have an impact on any of the conditions 
    of linear regression?
    
- ANSWER: Yes, this is an issue because professors likely receive similar ratings across their various courses. If certain professors teach more courses than others, their data are over represented in the model. The below df prof shows that 7 professors taught 10 or more courses, while 7 professors only taught 1 course. In addition, if certain students have the same professor for multiple courses, their data could be especially over represented. 

```{r}
library(dplyr)
prof <- table(evals$prof_id)
prof %>% as.data.frame() %>% arrange(desc(Freq))
```

18. Based on your final model, describe the characteristics of a professor and 
    course at University of Texas at Austin that would be associated with a high
    evaluation score.
    
- ANSWER: The characteristics most associated with receiving a high evaluation score are: Being male gender; Not being an ethnic minority; Having received an education at a predominantly English-language institution; Being young; Having a high beauty score; Having a high percentage of your class' students complete an evaluation; Having your class be one credit.

```{r}
summary(m_best)
```

19. Would you be comfortable generalizing your conclusions to apply to professors
    generally (at any university)? Why or why not?

- ANSWER: I would need more data to understand whether 1) The University of Texas is similar to other universities (racially, socioeconomically, gender ratio, etc.) and 2) Whether this study was taken from a random sample of UT students. If these two conditions were met, then I'd generally expect results to be similar at other universities. As a demonstration of how this survey could be limited if condition 1 was not met: A non-ethnically diverse school of majority men might on average have different world views than a different sort of school, leading to different course evaluations. While identity politics have limitations, demographic characteristics can be used to predict such things as voting patterns, therefore they could have statistically significant impacts on professor evaluations too. Regarding condition 2, random samples are essential to representing the entire population. Otherwise, this sample might not even represent the UT, let alone be generalizable to other universities. 

* * *
